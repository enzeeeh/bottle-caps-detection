# ğŸº Bottle Caps Detection

A comprehensive computer vision system for detecting bottle caps using YOLOv8, featuring a complete MLOps pipeline, web interface, and production-ready deployment.

## âœ¨ Features

- **ğŸ¯ High Accuracy**: 99.5% mAP@0.5 detection performance
- **âš¡ Real-time Processing**: ~10ms inference time per image
- **ğŸŒ Full-Stack Web App**: React frontend + FastAPI backend
- **ğŸ“Š MLOps Pipeline**: Complete training, evaluation, and monitoring
- **ğŸ³ Docker Ready**: Containerized deployment
- **ğŸ“š Comprehensive Documentation**: Detailed analysis and notebooks

## ğŸ—ï¸ Project Structure

```
bottle-caps-detection/
â”œâ”€â”€ ğŸ“ src/                          # Source code
â”‚   â”œâ”€â”€ ğŸ“ api/                      # FastAPI backend
â”‚   â”‚   â””â”€â”€ api.py                   # Main API application
â”‚   â””â”€â”€ ğŸ“ web/                      # Web interface
â”‚       â””â”€â”€ frontend/                # React application
â”œâ”€â”€ ğŸ“ bsort/                        # Core ML package
â”‚   â”œâ”€â”€ cli.py                       # Command line interface
â”‚   â”œâ”€â”€ config.py                    # Configuration management
â”‚   â”œâ”€â”€ ğŸ“ data/                     # Data processing
â”‚   â”œâ”€â”€ ğŸ“ models/                   # Model definitions
â”‚   â”œâ”€â”€ ğŸ“ pipeline/                 # ML pipeline
â”‚   â””â”€â”€ ğŸ“ train/                    # Training utilities
â”œâ”€â”€ ğŸ“ notebooks/                    # Jupyter notebooks
â”‚   â””â”€â”€ Model_Development_and_Experimentation.ipynb
â”œâ”€â”€ ğŸ“ docs/                         # Documentation
â”‚   â”œâ”€â”€ README_FULLSTACK.md          # Full-stack guide
â”‚   â””â”€â”€ README_PIPELINE.md           # Pipeline documentation
â”œâ”€â”€ ğŸ“ configs/                      # Configuration files
â”‚   â”œâ”€â”€ settings.yaml                # Main settings
â”‚   â””â”€â”€ settings_pipeline.yaml       # Pipeline config
â”œâ”€â”€ ğŸ“ models/                       # Trained models
â”‚   â””â”€â”€ yolov8n.pt                   # Pre-trained model
â”œâ”€â”€ ğŸ“ deployment/                   # Deployment files
â”‚   â”œâ”€â”€ ğŸ“ docker/                   # Docker configuration
â”‚   â”‚   â””â”€â”€ Dockerfile               # Container definition
â”‚   â””â”€â”€ ğŸ“ scripts/                  # Deployment scripts
â”‚       â”œâ”€â”€ start.ps1                # Windows startup
â”‚       â””â”€â”€ start.sh                 # Unix startup
â”œâ”€â”€ ğŸ“ data/                         # Dataset
â”œâ”€â”€ ğŸ“ sample/                       # Sample images
â”œâ”€â”€ ğŸ“ scripts/                      # Utility scripts
â”œâ”€â”€ ğŸ“ tests/                        # Test suite
â”œâ”€â”€ ğŸ“ runs/                         # Training outputs
â”œâ”€â”€ ğŸ“ wandb/                        # W&B experiment tracking
â”œâ”€â”€ requirements.txt                 # Dependencies
â”œâ”€â”€ pyproject.toml                   # Project configuration
â””â”€â”€ README.md                        # This file
```

## âš¡ Quick Start (Existing Users)

**If you already have the environment set up:**
```bash
cd bottle-caps-detection
conda activate bottle-detect

# Start the web app
.\deployment\scripts\start.ps1  # Windows
# OR analyze your model
jupyter notebook notebooks/Model_Development_and_Experimentation.ipynb
```

## ğŸš€ Full Setup (First Time)

### Prerequisites

- **Python 3.8+**
- **CUDA-compatible GPU** (recommended)
- **Node.js 16+** (for frontend)
- **Conda** or **virtualenv**

### ğŸ“¦ Installation

1. **Clone the repository:**
```bash
git clone https://github.com/enzeeeh/bottle-caps-detection.git
cd bottle-caps-detection
```

2. **Environment Setup:**

**If you already have the environment (existing users):**
```bash
conda activate bottle-detect
```

**For first-time setup:**
```bash
# Create the environment
conda create -n bottle-detect python=3.9
conda activate bottle-detect

# Install dependencies
pip install -r requirements.txt
```

3. **Verify installation:**
```bash
python -c "import torch; print('PyTorch:', torch.__version__)"
python -c "from ultralytics import YOLO; print('YOLOv8: Ready')"
```

### ğŸƒâ€â™‚ï¸ Running the Application

**Make sure your environment is activated:**
```bash
conda activate bottle-detect
```

#### ğŸŒ Full-Stack Web Application
```bash
# Windows
.\deployment\scripts\start.ps1

# Linux/Mac
./deployment/scripts/start.sh
```

**Access Points:**
- ğŸ–¥ï¸ **Frontend**: http://localhost:3000
- ğŸ”§ **API**: http://localhost:8000
- ğŸ“š **API Docs**: http://localhost:8000/docs

#### ğŸ”§ API Only
```bash
uvicorn src.api.api:app --host 0.0.0.0 --port 8000 --reload
```

## ğŸ“Š Model Performance

Our YOLOv8n model achieves exceptional performance:

| Metric | Value | Status |
|--------|--------|---------|
| **mAP@0.5** | 99.5% | ğŸŸ¢ Excellent |
| **mAP@0.5:0.95** | 85.1% | ğŸŸ¢ Very Good |
| **Precision** | 99.5% | ğŸŸ¢ Near Perfect |
| **Recall** | 100% | ğŸŸ¢ Perfect |
| **F1-Score** | 99.7% | ğŸŸ¢ Excellent |
| **Model Size** | ~6MB | âš¡ Lightweight |
| **Inference Time** | ~10ms | âš¡ Real-time |

## ğŸ”§ API Usage

### Upload and Detect
```bash
curl -X POST "http://localhost:8000/detect" \
     -H "accept: application/json" \
     -H "Content-Type: multipart/form-data" \
     -F "file=@your_image.jpg"
```

### Response Format
```json
{
  "detections": [
    {
      "confidence": 0.995,
      "bbox": [x1, y1, x2, y2],
      "class": "bottle_cap"
    }
  ],
  "count": 1,
  "inference_time": 0.01,
  "image_size": [640, 480]
}
```

## ğŸ“ Model Training & Experimentation

### ğŸ““ Comprehensive Analysis
Explore our detailed model development process:
```bash
jupyter notebook notebooks/Model_Development_and_Experimentation.ipynb
```

**Analysis Includes:**
- ğŸ“Š Dataset exploration and quality assessment
- ğŸ¯ Model architecture analysis
- ğŸ“ˆ Performance evaluation and metrics
- âš–ï¸ Bias analysis and fairness assessment
- ğŸ” Feature importance and interpretability
- ğŸ”„ Model comparison and alternatives

### ğŸš€ Training Your Model

**Two clear options for training:**

#### ğŸ““ **Interactive Analysis & Training (Recommended)**
```bash
conda activate bottle-detect
jupyter notebook notebooks/Model_Development_and_Experimentation.ipynb
```
*Use this for: Learning, analysis, experimentation, documentation*

#### âš¡ **Fast Production Training**
```bash
conda activate bottle-detect
python scripts/train_production.py --epochs 50 --batch-size 8
```
*Use this for: Quick training, production deployment, automated pipelines*

## ğŸ³ Docker Deployment

### Build and Run
```bash
# Build the image
docker build -f deployment/docker/Dockerfile -t bottle-caps-detection .

# Run the container
docker run -p 8000:8000 bottle-caps-detection
```

### Production Deployment
```bash
# With environment variables
docker run -p 8000:8000 \
  -e ENVIRONMENT=production \
  -e LOG_LEVEL=info \
  bottle-caps-detection
```

## ğŸ“š Documentation

- **ğŸ“– [Full-Stack Guide](docs/README_FULLSTACK.md)** - Complete web application setup
- **ğŸ““ [Model Development Notebook](notebooks/Model_Development_and_Experimentation.ipynb)** - Comprehensive analysis and training

## ğŸ§ª Testing

```bash
conda activate bottle-detect

# Run all tests
python -m pytest tests/ -v

# Run specific test categories
python -m pytest tests/test_api.py -v
python -m pytest tests/test_training.py -v
```

## ğŸ¤ Contributing

1. **Fork** the repository
2. **Create** a feature branch (`git checkout -b feature/amazing-feature`)
3. **Commit** your changes (`git commit -m 'Add amazing feature'`)
4. **Push** to the branch (`git push origin feature/amazing-feature`)
5. **Open** a Pull Request

### Development Setup
```bash
# Install development dependencies
pip install -r requirements.txt
pip install -e .

# Install pre-commit hooks
pre-commit install
```

## ğŸ“ˆ Roadmap

- [x] **Phase 1**: Core detection model
- [x] **Phase 2**: Web interface and API
- [x] **Phase 3**: Comprehensive analysis and documentation
- [ ] **Phase 4**: Enhanced data collection
- [ ] **Phase 5**: Production optimization
- [ ] **Phase 6**: Advanced features and monitoring

## ğŸ™ Acknowledgments

- **[Ultralytics YOLOv8](https://github.com/ultralytics/ultralytics)** - State-of-the-art object detection
- **[FastAPI](https://fastapi.tiangolo.com/)** - Modern Python web framework
- **[React](https://reactjs.org/)** - Frontend user interface
- **[Weights & Biases](https://wandb.ai/)** - Experiment tracking
- **[Docker](https://docker.com/)** - Containerization platform

## ğŸ“„ License

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

---

<div align="center">

**ğŸº Built with â¤ï¸ for bottle cap detection**

[![GitHub stars](https://img.shields.io/github/stars/enzeeeh/bottle-caps-detection?style=social)](https://github.com/enzeeeh/bottle-caps-detection)
[![GitHub forks](https://img.shields.io/github/forks/enzeeeh/bottle-caps-detection?style=social)](https://github.com/enzeeeh/bottle-caps-detection)

</div>